{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a GPT Output of GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 04:59:09.997246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# check if a gpu is available\n",
    "def check_gpu():\n",
    "    if tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None):\n",
    "        print(\"GPU is available\")\n",
    "    else:\n",
    "        print(\"GPU is not available\")\n",
    "\n",
    "check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:47:40.557019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 14:47:41.559155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define function to load and preprocess Pokémon dataset\n",
    "def load_and_preprocess_dataset(dataset_path, image_shape, batch_size):\n",
    "    # Create a dataset from image files\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset_path,\n",
    "        image_size=(image_shape[0], image_shape[1]),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    # Normalize pixel values to range [-1, 1]\n",
    "    dataset = dataset.map(lambda x, _: (x / 127.5) - 1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define dataset path, image shape, and batch size\n",
    "dataset_path = 'path/to/pokemon/dataset'\n",
    "image_shape = (64, 64)  # Adjust this according to your dataset\n",
    "batch_size = 32  # Adjust batch size according to your system memory\n",
    "\n",
    "# Load and preprocess Pokémon dataset\n",
    "pokemon_dataset = load_and_preprocess_dataset(dataset_path, image_shape, batch_size)\n",
    "\n",
    "# Print dataset shape\n",
    "for images, _ in pokemon_dataset.take(1):\n",
    "    print(\"Pokémon dataset shape:\", images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define function to load Pokémon dataset\n",
    "def load_pokemon_dataset(dataset_path, image_shape):\n",
    "    images = []\n",
    "    # Iterate over each Pokémon image file\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith('.png'):  # Assuming images are in PNG format\n",
    "            image = Image.open(os.path.join(dataset_path, filename))\n",
    "            # Resize the image to the desired shape\n",
    "            image = image.resize(image_shape[:2])\n",
    "            # Convert image to numpy array\n",
    "            image = np.array(image)\n",
    "            # Normalize pixel values to range [-1, 1]\n",
    "            image = (image.astype(np.float32) - 127.5) / 127.5\n",
    "            # Add image to the list\n",
    "            images.append(image)\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define dataset path and image shape\n",
    "dataset_path = 'path/to/pokemon/dataset'\n",
    "image_shape = (64, 64, 3)  # Adjust this according to your dataset\n",
    "\n",
    "# Load Pokémon dataset\n",
    "pokemon_data = load_pokemon_dataset(dataset_path, image_shape)\n",
    "\n",
    "# Shuffle the dataset\n",
    "pokemon_data = shuffle(pokemon_data)\n",
    "\n",
    "# Print dataset shape\n",
    "print(\"Pokémon dataset shape:\", pokemon_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load Pokémon dataset or any other dataset of your choice\n",
    "# For simplicity, let's assume we're using the MNIST dataset for now\n",
    "# You can replace this with your Pokémon dataset\n",
    "# (Make sure your dataset is preprocessed and resized to a suitable resolution)\n",
    "#(x_train, _), (_, _) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the generator model\n",
    "def build_generator(latent_dim, image_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, input_dim=latent_dim),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(256),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(512),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(np.prod(image_shape), activation='tanh'),\n",
    "        layers.Reshape(image_shape)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def build_discriminator(image_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=image_shape),\n",
    "        layers.Dense(512),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(256),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define GAN model (combined generator and discriminator)\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.Sequential([\n",
    "        generator,\n",
    "        discriminator\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define parameters\n",
    "latent_dim = 100\n",
    "image_shape = (28, 28, 1) # Adjust this to match your image size\n",
    "\n",
    "# Build and compile discriminator\n",
    "discriminator = build_discriminator(image_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build generator\n",
    "generator = build_generator(latent_dim, image_shape)\n",
    "\n",
    "# Build and compile GAN model\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "# Function to generate fake images\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "# Training loop\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, batch_size=128):\n",
    "    batch_per_epoch = dataset.shape[0] // batch_size\n",
    "    half_batch = batch_size // 2\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(batch_per_epoch):\n",
    "            # Train discriminator\n",
    "            x_real, y_real = dataset[np.random.randint(0, dataset.shape[0], half_batch)], np.ones((half_batch, 1))\n",
    "            d_loss_real = d_model.train_on_batch(x_real, y_real)\n",
    "            x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss_fake = d_model.train_on_batch(x_fake, y_fake)\n",
    "            # Train generator\n",
    "            x_gan = np.random.randn(latent_dim * batch_size)\n",
    "            x_gan = x_gan.reshape(batch_size, latent_dim)\n",
    "            y_gan = np.ones((batch_size, 1))\n",
    "            g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "            # Summarize progress\n",
    "            print(f'Epoch {epoch+1}/{n_epochs}, Batch {batch}/{batch_per_epoch}, D_loss_real={d_loss_real[0]}, D_loss_fake={d_loss_fake[0]}, G_loss={g_loss}')\n",
    "        # Visualize generated images\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            visualize_generated_images(generator, epoch+1)\n",
    "\n",
    "# Function to visualize generated images\n",
    "def visualize_generated_images(generator, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Train GAN\n",
    "#train(generator, discriminator, gan, x_train, latent_dim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ygo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
